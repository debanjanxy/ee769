\section{Conclusions}
We found the spectrogram representation of audio to be more efficient than the MFCC representation which is commonly used to solve speech recognition problem. Initially as we increased the number of convolution layers we saw improvement in achieved test accuracy but after four layers the test accuracy started decreasing. Also after introducing dropouts in our model the test accuracy improved. Dropouts reduced the amount of over-fitting. 
\par The main challenge in our project was computational power. That is we were not able to train our model in our laptop because it did not have enough main memory capacity. So we trained our model in lab machines but still it took considerable amount of time to train the model on the complete data set. 
\par For future work, we can use pre-trained models like VGG to extract features from spectrogram. And a multi-model ensemble method should work better on this problem. 