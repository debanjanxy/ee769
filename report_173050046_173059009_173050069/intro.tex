\section{Introduction}
Speech recognition is one of the most commonly available and used features in today's world. With IoT and smart-phones it has become quite easy to use voice commands to perform common tasks of setting reminders, alarms etc. But these features are usually implemented by giant organizations with abundant resources. These voice datasets require a large amount of prepossessing before a deep learning model can be built using them. For independent developers and entrepreneurs, it is still difficult to perform speech recognition in their projects. To help independent developers gain insights into speech recognition Tensorflow released a dataset of 65000 one second examples of 30 commonly used words by different people with sample freaquency 16kHz.
\par Speech recognition has a large number of applications like Apple, Google voice assistants, automated cars, any device with which user can interact by voice commands. With the advent of Google Home and Amazon Alexa, it has become common to use voice commands to perform daily tasks.
\par The task of converting voice signals to text input is challenging due to various reasons like surrounding noise, variability in accents, quality of input microphones, ambiguous words, which makes it difficult to transform it to a textual representation.
\par The idea behind speech recognition is to convert spoken words and phrases to text. Different approaches are used to convert raw audio input from user to digital representation. The commonly used feature for this transformation is MFCC which are coefficients of mel-frequency cepstrum which are power density representation of a sound. We have used sound spectrograms as input for our project. Spectrogram represents how voice frequencies change over time.
We used this spectrogram as input for four 1D CNN layers followed by three GRU layers. The trained model can currently classify 10 words with average test accuracy of 78.23\%.
